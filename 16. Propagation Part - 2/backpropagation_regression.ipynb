{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgnPvgw8DyOq"
   },
   "source": [
    "# Regression Example of BackPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iznsv0cPD4N2"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]], \n",
    "                  columns=['cgpa', 'profile_score', 'lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Icg8cssxEJ4U",
    "outputId": "faf04b08-f325-4e7c-eba6-e002fd3fbc9f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for defining Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gOL7f79VEKQn"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Initializes the parameters (weights and biases) for a neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    layer_dims -- List containing the dimensions of each layer in the network.\n",
    "                  Example: [input_size, hidden_layer1_size, ..., output_size]\n",
    "\n",
    "    Returns:\n",
    "    parameters -- Python dictionary containing the initialized parameters:\n",
    "                  parameters[\"W1\"] = weight matrix for layer 1\n",
    "                  parameters[\"b1\"] = bias vector for layer 1\n",
    "                  ...\n",
    "                  parameters[\"WL\"] = weight matrix for the last layer\n",
    "                  parameters[\"bL\"] = bias vector for the last layer\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(3)  # Set a seed for the random number generator for reproducibility\n",
    "    parameters = {}    # Initialize an empty dictionary to store the parameters\n",
    "    L = len(layer_dims)  # Number of layers in the network, including input and output layers\n",
    "\n",
    "    for l in range(1, L):\n",
    "        # Initialize weight matrix W for layer l with small values (here, all ones multiplied by 0.1)\n",
    "        parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l-1])) * 0.1\n",
    "        \n",
    "        # Initialize bias vector b for layer l with zeros\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "    return parameters  # Return the dictionary containing all the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkduRBgNIp-z",
    "outputId": "c0c32750-846b-499c-fc16-9f542ad3cdd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])   \n",
    "# In our neural network\n",
    "#We have 2 input parameter,2 Perceptron on input layer & 1 Perceptron on o/p layer\n",
    "#thatby we are passing '[2,2,1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZghmdgJzEg0D"
   },
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "    \"\"\"\n",
    "    This Function will calculate the output of given Neuron.\n",
    "    Implements the linear part of a layer's forward propagation.\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Activations from the previous layer (or input data), of shape (size of previous layer, number of examples)\n",
    "    W -- Weights matrix for the current layer, of shape (size of current layer, size of previous layer)\n",
    "    b -- Bias vector for the current layer, of shape (size of current layer, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- The input to the activation function, also called the pre-activation parameter\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the linear combination of inputs, weights, and Adding the biase value into it.\n",
    "    Z = np.dot(W.T, A_prev) + b\n",
    "    \n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation through the entire network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5n5DFL99Gacw"
   },
   "outputs": [],
   "source": [
    "def L_layer_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements forward propagation for the entire neural network.\n",
    "\n",
    "    Arguments:\n",
    "    X -- Input data, of shape (input size, number of examples)\n",
    "    parameters -- Python dictionary containing the parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                  Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                  bl -- bias vector of shape (layer_dims[l], 1)\n",
    "\n",
    "    Returns:\n",
    "    A -- The output of the final layer, which is the prediction of the network\n",
    "    A_prev -- The output of the second last layer (useful for certain cases like computing the gradient in backpropagation)\n",
    "    \"\"\"\n",
    "\n",
    "    A = X  # Initialize activation for the input layer (A0 = X)\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network (dividing by 2 since each layer has W and b)\n",
    "\n",
    "    # Loop over each layer to perform forward propagation\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A  # Store the activation from the previous layer\n",
    "        \n",
    "        # Retrieve the parameters for the current layer l\n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "        \n",
    "        # Perform the linear step for the current layer\n",
    "        A = linear_forward(A_prev, Wl, bl)\n",
    "        \n",
    "        # Uncomment these lines if you want to debug and see the values at each layer\n",
    "        #print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "        #print(\"W\"+str(l)+\": \", Wl)\n",
    "        #print(\"b\"+str(l)+\": \", bl)\n",
    "        #print(\"--\" * 20)\n",
    "        #print(\"A\"+str(l)+\": \", A)\n",
    "        #print(\"**\" * 20)\n",
    "\n",
    "    return A, A_prev  # Return the output of the final layer and the second last layer's activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ijULWqvJu0O",
    "outputId": "195c3602-d8a5-44a4-d224-278cd274a0ec"
   },
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Predication on 1st row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZrhNecsGML3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predication of model on 1st row input(y_cap) 0.32000000000000006\n"
     ]
    }
   ],
   "source": [
    "y_hat = y_hat[0][0]\n",
    "print(\"Predication of model on 1st row input(y_cap)\",y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWPvGGQcJ-Wq",
    "outputId": "2700de8a-b50d-4183-f277-0b21a5210def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of Intermediate layers means two neurons: [[1.6]\n",
      " [1.6]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Output of Intermediate layers means two neurons:\",A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Find error of that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of that Particular Student 13.5424\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss of that Particular Student\",(y-0.32)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step:4 Update Parameters\n",
    "```python\n",
    "This function will update all nine parameter \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EQWgVKAyNIr2"
   },
   "outputs": [],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTSNat7KNTm7",
    "outputId": "f3d3d349-c993-4d2f-a720-48e0e8433db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10658137, 0.10658137],\n",
       "        [0.10658137, 0.10658137]]),\n",
       " 'b1': array([[0.00082267],\n",
       "        [0.00082267]]),\n",
       " 'W2': array([[0.111776, 0.1     ],\n",
       "        [0.111776, 0.1     ]]),\n",
       " 'b2': array([[0.119136]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reapeat the processs again(Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 2nd Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bT36dOGNNijU",
    "outputId": "050e03e6-b792-474e-b4ad-a41c07ab6687"
   },
   "outputs": [],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[1][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predication of model on 1st row input(y_cap) 0.46036092108800003\n"
     ]
    }
   ],
   "source": [
    "y_hat = y_hat[1][0]\n",
    "print(\"Predication of model on 1st row input(y_cap)\",y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of Intermediate layers means two neurons: [[1.70612461]\n",
      " [1.70612461]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Output of Intermediate layers means two neurons:\",A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of that Particular Student 21.902399999999997\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss of that Particular Student\",(y-0.32)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kXN473kWNq2F"
   },
   "outputs": [],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjKso9pQNti8",
    "outputId": "56ff54b1-5b11-44d2-974e-849989291bad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.11466978, 0.11698075],\n",
       "        [0.11466978, 0.11698075]]),\n",
       " 'b1': array([[0.00197816],\n",
       "        [0.00197816]]),\n",
       " 'W2': array([[0.12726638, 0.1       ],\n",
       "        [0.12726638, 0.1       ]]),\n",
       " 'b2': array([[0.13634566]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyWoiZWYL8ft"
   },
   "source": [
    "### For 3rd Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-gTVDlsYoFm",
    "outputId": "f594df70-332f-4144-e903-870185a4a1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predication of model on 1st row input(y_cap) 0.32000000000000006\n",
      "Output of Intermediate layers means two neurons: [[1.6]\n",
      " [1.6]]\n",
      "Loss of that Particular Student 32.2624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10805488, 0.11342479],\n",
       "        [0.10805488, 0.11342479]]),\n",
       " 'b1': array([[0.00134248],\n",
       "        [0.00134248]]),\n",
       " 'W2': array([[0.118176, 0.1     ],\n",
       "        [0.118176, 0.1     ]]),\n",
       " 'b2': array([[0.129536]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[2].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[2][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "print(\"Predication of model on 1st row input(y_cap)\",y_hat)\n",
    "print(\"Output of Intermediate layers means two neurons:\",A1)\n",
    "print(\"Loss of that Particular Student\",(y-0.32)**2)\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 4th Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vog84hecfGI7",
    "outputId": "09e6fcb3-2534-468f-e5f5-89e4743097d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predication of model on 1st row input(y_cap) 0.5748041823921767\n",
      "Output of Intermediate layers means two neurons: [[1.83827537]\n",
      " [1.92956397]]\n",
      "Loss of that Particular Student 44.6224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.11716571, 0.1352908 ],\n",
       "        [0.11724108, 0.13547169]]),\n",
       " 'b1': array([[0.00316465],\n",
       "        [0.00317972]]),\n",
       " 'W2': array([[0.14179856, 0.1       ],\n",
       "        [0.14297165, 0.1       ]]),\n",
       " 'b2': array([[0.15582204]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[3].reshape(2,1) # Shape(no of features, no. of training exaplme)\n",
    "y = df[['lpa']].values[3][0]\n",
    "\n",
    "y_hat,A1 = L_layer_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "print(\"Predication of model on 1st row input(y_cap)\",y_hat)\n",
    "print(\"Output of Intermediate layers means two neurons:\",A1)\n",
    "print(\"Loss of that Particular Student\",(y-0.32)**2)\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs implementation (Working of outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-ZcZmJafwkc",
    "outputId": "8af42b77-b968-4b76-e598-8e6006a56219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss -  25.321744156025517\n",
      "Epoch -  2 Loss -  18.320004165722047\n",
      "Epoch -  3 Loss -  9.473661050729628\n",
      "Epoch -  4 Loss -  3.2520938634031613\n",
      "Epoch -  5 Loss -  1.3407132589299962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.26507636, 0.38558861],\n",
       "        [0.27800387, 0.40980287]]),\n",
       " 'b1': array([[0.02749056],\n",
       "        [0.02974394]]),\n",
       " 'W2': array([[0.41165744, 0.1       ],\n",
       "        [0.48302736, 0.1       ]]),\n",
       " 'b2': array([[0.48646246]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append((y-y_hat)**2)\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
